{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from nltk.corpus import stopwords  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Two imprisoned men bond over a number of years, finding solace and eventual redemption through acts of common decency.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data = pd.read_csv(\"movies.csv\")\n",
    "\n",
    "def split_genres(genres):\n",
    "    return genres.replace(\" \", \"\").split(\",\")\n",
    "movie_data[\"Genre\"] = movie_data[\"Genre\"].apply(split_genres)\n",
    "movie_data[\"Description\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(movie_data.Genre)\n",
    "Y = multilabel_binarizer.transform(movie_data.Genre)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(movie_data.Description)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(X_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sukrucan/.local/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=9000)\n",
    "X_tfidf_resampled, Y_tfidf_resampled = ros.fit_sample(X_tfidf, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfidf, x_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf_resampled, Y_tfidf_resampled, test_size=0.2, random_state=9000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    '''\n",
    "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
    "    http://stackoverflow.com/q/32239577/395857\n",
    "    '''\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/float(len(set_true.union(set_pred)) )\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)\n",
    "\n",
    "def print_score(y_pred, clf):\n",
    "    print(\"Hamming loss: {}\".format(hamming_loss(y_pred, y_test_tfidf)))\n",
    "    print(\"Hamming score: {}\".format(hamming_score(y_pred, y_test_tfidf)))\n",
    "    print(\"---\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  :  MultinomialNB\n",
      "Hamming loss: 0.01848807506512557\n",
      "Hamming score: 0.6587456496730885\n",
      "---\n",
      "model  :  SGDClassifier\n",
      "Hamming loss: 0.027952148511596147\n",
      "Hamming score: 0.4691975012013455\n",
      "---\n",
      "model  :  LogisticRegression\n",
      "Hamming loss: 0.01486633450517211\n",
      "Hamming score: 0.7232580490148967\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "nb_clf = MultinomialNB()\n",
    "sgd = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=100, tol=None)\n",
    "lr = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "for classifier in [nb_clf, sgd, lr]:\n",
    "    print(\"model  : \", classifier.__class__.__name__)\n",
    "    clf = OneVsRestClassifier(classifier)\n",
    "    clf.fit(x_train_tfidf, y_train_tfidf)\n",
    "    y_pred = clf.predict(x_test_tfidf)\n",
    "    print_score(y_pred, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime',\n",
       "       'Drama', 'Family', 'Fantasy', 'FilmNoir', 'History', 'Horror',\n",
       "       'Music', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Sport',\n",
       "       'Thriller', 'War', 'Western'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_binarizer.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = movie_data[[\"Description\",\"Genre\"]]\n",
    "new_data\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(new_data.Genre)\n",
    "Y = multilabel_binarizer.transform(new_data.Genre)\n",
    "x = new_data[\"Description\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"glove.6B.200d.pkl\", 'rb') as f:\n",
    "    word_vector = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import scipy.stats as ss\n",
    "    \n",
    "tf = TfidfVectorizer( analyzer='word',min_df = 0, stop_words = 'english', sublinear_tf=True)\n",
    "tfidf_matrix =  tf.fit_transform(x)\n",
    "feature_names = tf.get_feature_names()\n",
    "x_v = []\n",
    "for docId in range(len(x)):\n",
    "    doc = docId\n",
    "    feature_index = tfidf_matrix[doc,:].nonzero()[1]\n",
    "    tfidf_scores = zip(feature_index, [tfidf_matrix[doc, x] for x in feature_index])\n",
    "    docWector = []\n",
    "    wordNos = 0\n",
    "    for w, s in [(feature_names[i], s) for (i, s) in tfidf_scores]:\n",
    "        if w in word_vector:\n",
    "            wordNos+=1\n",
    "            docWector.append(word_vector[w]*s)\n",
    "    docWector = sum(docWector)/len(docWector)\n",
    "    x_v.append(docWector)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "smote_tomek = RandomOverSampler(random_state=9000)\n",
    "X_resampled, Y_resampled = smote_tomek.fit_sample(x_v, Y)\n",
    "\n",
    "_, X_new, _, y_new = train_test_split(X_resampled, Y_resampled, test_size=0.20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.20, random_state=42)\n",
    "\n",
    "    \n",
    "def mlknn(train_data, train_label, test_data, k):\n",
    "    test_labels = []\n",
    "    for test in test_data:\n",
    "        distances = [ distance.cosine(test,x) for x in train_data]\n",
    "        ranking = ss.rankdata(distances, method='ordinal')\n",
    "        firstKindexes = [np.where(x == ranking) for x in range(1,k+1)]\n",
    "        allLabels = sum([train_label[index[0][0]] for index in firstKindexes])\n",
    "        pickLabels = allLabels/sum(allLabels)\n",
    "        maxLabels = np.where(max(pickLabels) == pickLabels )[0]\n",
    "        test_label = [0 for x in pickLabels]\n",
    "        for i in maxLabels:\n",
    "            test_label[i] = 1\n",
    "        test_labels.append(test_label)\n",
    "    return test_labels\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming score for k =1 : 0.8226814031715521\n",
      "Hamming score for k =2 : 0.7864007688611244\n",
      "Hamming score for k =3 : 0.7728656094826206\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    test_return = mlknn(X_train, y_train, X_test,i)\n",
    "    print(\"Hamming score for k ={} : {}\".format(i,hamming_score(np.array(test_return), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8324, 200)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
